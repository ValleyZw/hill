{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scientific Python imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the digits dataset\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect dataset\n",
    "SAMPLE = 0\n",
    "(ROW, COL) = (5, 5)\n",
    "(WIDTH, HEIGHT) = np.shape(digits.images[SAMPLE])\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:ROW*COL]):\n",
    "    plt.subplot(ROW, COL, index + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "print(f'{digits.target[SAMPLE]} -> {WIDTH} x {HEIGHT}\\n {digits.images[SAMPLE]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variable into dummy/indicator variables\n",
    "labels = digits.target.reshape(len(digits.target),1) \n",
    "enc = OneHotEncoder()\n",
    "enc.fit(labels)\n",
    "onehotlabels = enc.transform(labels).toarray()\n",
    "print(f'{digits.target[SAMPLE]} -> {onehotlabels[SAMPLE]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper_images = [np.reshape(i, (WIDTH*HEIGHT)) for i in digits.images]\n",
    "wrapper_labels = onehotlabels\n",
    "\n",
    "print(f'images -> {np.shape(wrapper_images)}, labels -> {np.shape(wrapper_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(wrapper_images, wrapper_labels, test_size=0.33, random_state=42)\n",
    "# convert matrix to (features x numbers)\n",
    "X_train = np.array(X_train).T\n",
    "X_test = np.array(X_test).T\n",
    "y_train = np.array(y_train).T\n",
    "y_test = np.array(y_test).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, neurons):\n",
    "        self._layers = len(neurons)\n",
    "        self._neurons = neurons\n",
    "        self._weights = [np.random.randn(nex, pre+1) for pre, nex in zip(neurons[:-1], neurons[1:])]\n",
    "     \n",
    "    def _sigmoid(self, x):\n",
    "        return 1.0/(1.0 + np.exp(-x))\n",
    "    \n",
    "    def _sigmoid_prime(self, x):\n",
    "        return self._sigmoid(x)*(1 - self._sigmoid(x))\n",
    "    \n",
    "    def feedforward(self, a):\n",
    "        z_s = []\n",
    "        a_s = []\n",
    "        for w in self._weights:\n",
    "            a = np.r_[np.ones((1, a.shape[1])), a]\n",
    "            a_s.append(a)\n",
    "            z = w.dot(a)\n",
    "            a = self._sigmoid(z)\n",
    "            z_s.append(z)\n",
    "        a_s.append(a)\n",
    "        return (a, z_s, a_s)\n",
    "    \n",
    "    def backprop(self, y_hat, y, z_s, a_s):\n",
    "        delta_weights = [np.zeros(w.shape) for w in self._weights]\n",
    "        # Update last layer delta\n",
    "        delta = a_s[-1] - y\n",
    "        delta_weights[-1] = np.dot(delta, a_s[-2].T)\n",
    "        # Update all but the last layer delta\n",
    "        for L in range(2, self._layers):\n",
    "            delta = self._weights[-L+1].T.dot(delta)[1:] * self._sigmoid_prime(z_s[-L])\n",
    "            delta_weights[-L] = np.dot(delta, a_s[-L-1].T) \n",
    "        return delta_weights\n",
    "    \n",
    "    def fit(self, x, y, iterations = 1000, learning_rate=0.001):\n",
    "        # batch GD\n",
    "        for i in range(iterations):\n",
    "            (y_hat, z_s, a_s) = self.feedforward(x)\n",
    "            delta_weights = self.backprop(y_hat, y, z_s, a_s)\n",
    "            # Update weights of each layers\n",
    "            self._weights = [w - learning_rate * dw for w, dw in zip(self._weights, delta_weights)]\n",
    "    \n",
    "    def predict(self, x):\n",
    "        (y_hat, z_s, a_s) = self.feedforward(x)\n",
    "        return y_hat\n",
    "    \n",
    "    def score(self, y_pred, y_test):\n",
    "        return sum(int(np.argmax(x) == np.argmax(y)) for (x, y) in zip(y_pred.T, y_test.T)) / y_pred.shape[1] * 100\n",
    "        \n",
    "    def get_cost(self, y_hat, y):\n",
    "        return -1/y.shape[1] * (y * np.log(y_hat+0.0001) + (1-y) * np.log(1-y_hat+0.0001)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "neurons = [64, 64, 64, 10]\n",
    "nn = NeuralNetwork(neurons)\n",
    "nn.fit(X_train, y_train, iterations=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nn.predict(X_test)\n",
    "nn.score(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
